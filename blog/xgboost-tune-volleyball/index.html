<!DOCTYPE html>
<html lang="en" dir="ltr"><head>
  
                           
     


<meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="generator" content="Hugo 0.91.2" />
<title>Tune XGBoost with tidymodels and #TidyTuesday beach volleyball | Julia Silge</title>


<meta property="twitter:site" content="@juliasilge">
<meta property="twitter:creator" content="@juliasilge">







  
    
  
<meta name="description" content="A data science blog">


<meta property="og:site_name" content="Julia Silge">
<meta property="og:title" content="Tune XGBoost with tidymodels and #TidyTuesday beach volleyball | Julia Silge">
<meta property="og:description" content="A data science blog" />
<meta property="og:type" content="page" />
<meta property="og:url" content="https://juliasilge.com/blog/xgboost-tune-volleyball/" />
<meta property="og:locale" content="en">




    
        <meta property="og:image" content="https://juliasilge.com/blog/xgboost-tune-volleyball/featured.png" >
        <meta property="twitter:card" content="summary_large_image">
        <meta name="twitter:image" content="https://juliasilge.com/blog/xgboost-tune-volleyball/featured.png" >
    
    
  <meta itemprop="name" content="Tune XGBoost with tidymodels and #TidyTuesday beach volleyball">
<meta itemprop="description" content="Learn how to tune hyperparameters for an XGBoost classification model to predict wins and losses."><meta itemprop="datePublished" content="2020-05-21T00:00:00+00:00" />
<meta itemprop="dateModified" content="2020-05-21T00:00:00+00:00" />
<meta itemprop="wordCount" content="2258"><meta itemprop="image" content="https://juliasilge.com/blog/xgboost-tune-volleyball/featured.png">
<meta itemprop="keywords" content="rstats,tidymodels," />
  
  
  <!--[if IE]><script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script><![endif]-->
  <link rel="shortcut icon" href="/img/icon.png" type="image/x-icon">
  <link rel="icon" href="/img/icon.png" type="image/x-icon">
  
  
  <link rel="stylesheet" href="/style.main.min.34750661ca065ca7ddb87b2b28cab82abf493a21c1e3852e0755fba776b031b7.css" integrity="sha256-NHUGYcoGXKfduHsrKMq4Kr9JOiHB44UuB1X7p3awMbc=" media="screen">
  
  
  <script src="/panelset.min.078a92db9bd3228df502db3d9e0453c3cf3d910abe3f8deca0ad196c7071ad41.js" type="text/javascript"></script>
  
  
  <script src="/main.min.bb67dea4a2ee41aab688effd180f2d02662e47280f0021495f2c0ce24c461f65.js" type="text/javascript"></script>
</head>
<body>
      <div class="grid-container">
<header class="site-header pt4 pb2 mb4 bb b--transparent ph5 headroom z-max" role="banner">
  <nav class="site-nav db dt-l w-100" role="navigation">
    <a class="site-brand db dtc-l v-mid link no-underline w-100 w-33-l tc tl-l" href="https://juliasilge.com/" title="Home">
      <span class="f4 fw7">Julia Silge</span>
    </a>
    <div class="site-links db dtc-l v-mid w-100 w-47-l tc tr-l mt3 mt0-l ttu tracked">
      
        
        
        
      <a class="link f6 f5-l dib pv1 ph2 " href="/about/" title="About me">About</a>
      
        
        
        
      <a class="link f6 f5-l dib pv1 ph2 active" href="/blog/" title="Blog">Blog</a>
      
      
    </div>
  </nav>
</header>

<main class="page-main pa4" role="main">
  <section class="page-content mw7 center">
    <article class="post-content pa0 ph4-l">
      <header class="post-header">
        <h1 class="f1 lh-solid measure-narrow mb3 fw4">Tune XGBoost with tidymodels and #TidyTuesday beach volleyball</h1>
        
        <p class="f6 measure lh-copy mv1"> in <a href="https://juliasilge.com/categories/rstats">rstats</a>  <a href="https://juliasilge.com/categories/tidymodels">tidymodels</a> </p>
        <p class="f7 db mv0 ttu">May 21, 2020</p>

      

      </header>
      <section class="post-body pt5 pb4">
        <p>Lately I&rsquo;ve been publishing 
<a href="https://juliasilge.com/category/tidymodels/" target="_blank" rel="noopener">screencasts</a> demonstrating how to use the 
<a href="https://www.tidymodels.org/" target="_blank" rel="noopener">tidymodels</a> framework, starting from just getting started. Today&rsquo;s screencast explores a more advanced topic in how to tune an XGBoost classification model using with this week&rsquo;s 
<a href="https://github.com/rfordatascience/tidytuesday" target="_blank" rel="noopener"><code>#TidyTuesday</code> dataset</a> on beach volleyball. ğŸ</p>
<!--html_preserve-->
<div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;">
  <iframe src="https://www.youtube-nocookie.com/embed/hpudxAmxHSM" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;" allowfullscreen title="YouTube Video"></iframe>
</div>
<!--/html_preserve-->
</br>
<p>Here is the code I used in the video, for those who prefer reading instead of or in addition to video.</p>




<h2 id="explore-the-data">Explore the data
  <a href="#explore-the-data"><svg class="anchor-symbol" aria-hidden="true" height="26" width="26" viewBox="0 0 22 22" xmlns="http://www.w3.org/2000/svg">
      <path d="M0 0h24v24H0z" fill="currentColor"></path>
      <path d="M3.9 12c0-1.71 1.39-3.1 3.1-3.1h4V7H7c-2.76.0-5 2.24-5 5s2.24 5 5 5h4v-1.9H7c-1.71.0-3.1-1.39-3.1-3.1zM8 13h8v-2H8v2zm9-6h-4v1.9h4c1.71.0 3.1 1.39 3.1 3.1s-1.39 3.1-3.1 3.1h-4V17h4c2.76.0 5-2.24 5-5s-2.24-5-5-5z"></path>
    </svg></a>
</h2>
<p>Our modeling goal is to predict whether a beach volleyball team of two won their match based on 
<a href="https://github.com/rfordatascience/tidytuesday/blob/master/data/2020/2020-05-19/readme.md" target="_blank" rel="noopener">game play stats like errors, blocks, attacks, etc from this week&rsquo;s #TidyTuesday dataset</a> . This dataset is quite extensive so it&rsquo;s a great opportunity to try a more powerful machine learning algorithm like XGBoost. This model has lots of tuning parameters!</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f0f0f0;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-r" data-lang="r">vb_matches <span style="color:#666">&lt;-</span> readr<span style="color:#666">::</span><span style="color:#06287e">read_csv</span>(<span style="color:#4070a0">&#39;https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-05-19/vb_matches.csv&#39;</span>, guess_max <span style="color:#666">=</span> <span style="color:#40a070">76000</span>)

vb_matches
</code></pre></div><pre tabindex="0"><code>## # A tibble: 76,756 x 65
##    circuit tournament country  year date       gender match_num w_player1
##    &lt;chr&gt;   &lt;chr&gt;      &lt;chr&gt;   &lt;dbl&gt; &lt;date&gt;     &lt;chr&gt;      &lt;dbl&gt; &lt;chr&gt;    
##  1 AVP     Huntingtoâ€¦ Unitedâ€¦  2002 2002-05-24 M              1 Kevin Woâ€¦
##  2 AVP     Huntingtoâ€¦ Unitedâ€¦  2002 2002-05-24 M              2 Brad Torâ€¦
##  3 AVP     Huntingtoâ€¦ Unitedâ€¦  2002 2002-05-24 M              3 Eduardo â€¦
##  4 AVP     Huntingtoâ€¦ Unitedâ€¦  2002 2002-05-24 M              4 Brent Doâ€¦
##  5 AVP     Huntingtoâ€¦ Unitedâ€¦  2002 2002-05-24 M              5 Albert Hâ€¦
##  6 AVP     Huntingtoâ€¦ Unitedâ€¦  2002 2002-05-24 M              6 Jason Riâ€¦
##  7 AVP     Huntingtoâ€¦ Unitedâ€¦  2002 2002-05-24 M              7 Aaron Boâ€¦
##  8 AVP     Huntingtoâ€¦ Unitedâ€¦  2002 2002-05-24 M              8 Canyon Câ€¦
##  9 AVP     Huntingtoâ€¦ Unitedâ€¦  2002 2002-05-24 M              9 Dax Holdâ€¦
## 10 AVP     Huntingtoâ€¦ Unitedâ€¦  2002 2002-05-24 M             10 Mark Wilâ€¦
## # â€¦ with 76,746 more rows, and 57 more variables: w_p1_birthdate &lt;date&gt;,
## #   w_p1_age &lt;dbl&gt;, w_p1_hgt &lt;dbl&gt;, w_p1_country &lt;chr&gt;, w_player2 &lt;chr&gt;,
## #   w_p2_birthdate &lt;date&gt;, w_p2_age &lt;dbl&gt;, w_p2_hgt &lt;dbl&gt;, w_p2_country &lt;chr&gt;,
## #   w_rank &lt;chr&gt;, l_player1 &lt;chr&gt;, l_p1_birthdate &lt;date&gt;, l_p1_age &lt;dbl&gt;,
## #   l_p1_hgt &lt;dbl&gt;, l_p1_country &lt;chr&gt;, l_player2 &lt;chr&gt;, l_p2_birthdate &lt;date&gt;,
## #   l_p2_age &lt;dbl&gt;, l_p2_hgt &lt;dbl&gt;, l_p2_country &lt;chr&gt;, l_rank &lt;chr&gt;,
## #   score &lt;chr&gt;, duration &lt;time&gt;, bracket &lt;chr&gt;, round &lt;chr&gt;,
## #   w_p1_tot_attacks &lt;dbl&gt;, w_p1_tot_kills &lt;dbl&gt;, w_p1_tot_errors &lt;dbl&gt;,
## #   w_p1_tot_hitpct &lt;dbl&gt;, w_p1_tot_aces &lt;dbl&gt;, w_p1_tot_serve_errors &lt;dbl&gt;,
## #   w_p1_tot_blocks &lt;dbl&gt;, w_p1_tot_digs &lt;dbl&gt;, w_p2_tot_attacks &lt;dbl&gt;,
## #   w_p2_tot_kills &lt;dbl&gt;, w_p2_tot_errors &lt;dbl&gt;, w_p2_tot_hitpct &lt;dbl&gt;,
## #   w_p2_tot_aces &lt;dbl&gt;, w_p2_tot_serve_errors &lt;dbl&gt;, w_p2_tot_blocks &lt;dbl&gt;,
## #   w_p2_tot_digs &lt;dbl&gt;, l_p1_tot_attacks &lt;dbl&gt;, l_p1_tot_kills &lt;dbl&gt;,
## #   l_p1_tot_errors &lt;dbl&gt;, l_p1_tot_hitpct &lt;dbl&gt;, l_p1_tot_aces &lt;dbl&gt;,
## #   l_p1_tot_serve_errors &lt;dbl&gt;, l_p1_tot_blocks &lt;dbl&gt;, l_p1_tot_digs &lt;dbl&gt;,
## #   l_p2_tot_attacks &lt;dbl&gt;, l_p2_tot_kills &lt;dbl&gt;, l_p2_tot_errors &lt;dbl&gt;,
## #   l_p2_tot_hitpct &lt;dbl&gt;, l_p2_tot_aces &lt;dbl&gt;, l_p2_tot_serve_errors &lt;dbl&gt;,
## #   l_p2_tot_blocks &lt;dbl&gt;, l_p2_tot_digs &lt;dbl&gt;
</code></pre><p>This dataset has the match stats like serve errors, kills, and so forth divided out by the two players for each team, but we want those combined together because we are going to make a prediction <strong>per team</strong> (i.e. what makes a team more likely to win). Let&rsquo;s include predictors like gender, circuit, and year in our model along with the per-match statistics. Let&rsquo;s omit matches with <code>NA</code> values because we don&rsquo;t have all kinds of statistics measured for all matches.</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f0f0f0;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-r" data-lang="r">vb_parsed <span style="color:#666">&lt;-</span> vb_matches <span style="color:#666">%&gt;%</span>
  <span style="color:#06287e">transmute</span>(
    circuit,
    gender,
    year,
    w_attacks <span style="color:#666">=</span> w_p1_tot_attacks <span style="color:#666">+</span> w_p2_tot_attacks,
    w_kills <span style="color:#666">=</span> w_p1_tot_kills <span style="color:#666">+</span> w_p2_tot_kills,
    w_errors <span style="color:#666">=</span> w_p1_tot_errors <span style="color:#666">+</span> w_p2_tot_errors,
    w_aces <span style="color:#666">=</span> w_p1_tot_aces <span style="color:#666">+</span> w_p2_tot_aces,
    w_serve_errors <span style="color:#666">=</span> w_p1_tot_serve_errors <span style="color:#666">+</span> w_p2_tot_serve_errors,
    w_blocks <span style="color:#666">=</span> w_p1_tot_blocks <span style="color:#666">+</span> w_p2_tot_blocks,
    w_digs <span style="color:#666">=</span> w_p1_tot_digs <span style="color:#666">+</span> w_p2_tot_digs,
    l_attacks <span style="color:#666">=</span> l_p1_tot_attacks <span style="color:#666">+</span> l_p2_tot_attacks,
    l_kills <span style="color:#666">=</span> l_p1_tot_kills <span style="color:#666">+</span> l_p2_tot_kills,
    l_errors <span style="color:#666">=</span> l_p1_tot_errors <span style="color:#666">+</span> l_p2_tot_errors,
    l_aces <span style="color:#666">=</span> l_p1_tot_aces <span style="color:#666">+</span> l_p2_tot_aces,
    l_serve_errors <span style="color:#666">=</span> l_p1_tot_serve_errors <span style="color:#666">+</span> l_p2_tot_serve_errors,
    l_blocks <span style="color:#666">=</span> l_p1_tot_blocks <span style="color:#666">+</span> l_p2_tot_blocks,
    l_digs <span style="color:#666">=</span> l_p1_tot_digs <span style="color:#666">+</span> l_p2_tot_digs
  ) <span style="color:#666">%&gt;%</span>
  <span style="color:#06287e">na.omit</span>()
</code></pre></div><p>Still plenty of data! Next, let&rsquo;s create separate dataframes for the winners and losers of each match, and then bind them together. I am using functions like <code>rename_with()</code> from the 
<a href="https://www.tidyverse.org/blog/2020/05/dplyr-1-0-0-last-minute-additions/" target="_blank" rel="noopener">upcoming dplyr 1.0 release here</a>.</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f0f0f0;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-r" data-lang="r">winners <span style="color:#666">&lt;-</span> vb_parsed <span style="color:#666">%&gt;%</span>
  <span style="color:#06287e">select</span>(circuit, gender, year,
         w_attacks<span style="color:#666">:</span>w_digs) <span style="color:#666">%&gt;%</span>
  <span style="color:#06287e">rename_with</span>(<span style="color:#666">~</span> <span style="color:#06287e">str_remove_all</span>(., <span style="color:#4070a0">&#34;w_&#34;</span>), w_attacks<span style="color:#666">:</span>w_digs) <span style="color:#666">%&gt;%</span>
  <span style="color:#06287e">mutate</span>(win <span style="color:#666">=</span> <span style="color:#4070a0">&#34;win&#34;</span>)

losers <span style="color:#666">&lt;-</span> vb_parsed <span style="color:#666">%&gt;%</span>
  <span style="color:#06287e">select</span>(circuit, gender, year,
         l_attacks<span style="color:#666">:</span>l_digs) <span style="color:#666">%&gt;%</span>
  <span style="color:#06287e">rename_with</span>(<span style="color:#666">~</span> <span style="color:#06287e">str_remove_all</span>(., <span style="color:#4070a0">&#34;l_&#34;</span>), l_attacks<span style="color:#666">:</span>l_digs) <span style="color:#666">%&gt;%</span>
  <span style="color:#06287e">mutate</span>(win <span style="color:#666">=</span> <span style="color:#4070a0">&#34;lose&#34;</span>)

vb_df <span style="color:#666">&lt;-</span> <span style="color:#06287e">bind_rows</span>(winners, losers) <span style="color:#666">%&gt;%</span>
  <span style="color:#06287e">mutate_if</span>(is.character, factor)
</code></pre></div><p>This is a similar 
<a href="https://twitter.com/JoshDoesa/status/1262738031636672516" target="_blank" rel="noopener">data prep approach to Joshua Cook</a>.</p>
<p>Exploratory data analysis is always important before modeling. Let&rsquo;s make one plot to explore the relationships in this data.</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f0f0f0;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-r" data-lang="r">vb_df <span style="color:#666">%&gt;%</span>
  <span style="color:#06287e">pivot_longer</span>(attacks<span style="color:#666">:</span>digs, names_to <span style="color:#666">=</span> <span style="color:#4070a0">&#34;stat&#34;</span>, values_to <span style="color:#666">=</span> <span style="color:#4070a0">&#34;value&#34;</span>) <span style="color:#666">%&gt;%</span>
  <span style="color:#06287e">ggplot</span>(<span style="color:#06287e">aes</span>(gender, value, fill <span style="color:#666">=</span> win, color <span style="color:#666">=</span> win)) <span style="color:#666">+</span>
  <span style="color:#06287e">geom_boxplot</span>(alpha <span style="color:#666">=</span> <span style="color:#40a070">0.4</span>) <span style="color:#666">+</span>
  <span style="color:#06287e">facet_wrap</span>(<span style="color:#666">~</span>stat, scales <span style="color:#666">=</span> <span style="color:#4070a0">&#34;free_y&#34;</span>, nrow <span style="color:#666">=</span> <span style="color:#40a070">2</span>) <span style="color:#666">+</span>
  <span style="color:#06287e">labs</span>(y <span style="color:#666">=</span> <span style="color:#007020;font-weight:bold">NULL</span>, color <span style="color:#666">=</span> <span style="color:#007020;font-weight:bold">NULL</span>, fill <span style="color:#666">=</span> <span style="color:#007020;font-weight:bold">NULL</span>)
</code></pre></div><img src="/blog/xgboost-tune-volleyball/index_files/figure-html/unnamed-chunk-5-1.png" width="2400" />
<p>We can see differences in errors and blocks especially. There are lots more great examples of #TidyTuesday EDA out there to explore on 
<a href="https://twitter.com/hashtag/TidyTuesday" target="_blank" rel="noopener">Twitter</a>!</p>




<h2 id="build-a-model">Build a model
  <a href="#build-a-model"><svg class="anchor-symbol" aria-hidden="true" height="26" width="26" viewBox="0 0 22 22" xmlns="http://www.w3.org/2000/svg">
      <path d="M0 0h24v24H0z" fill="currentColor"></path>
      <path d="M3.9 12c0-1.71 1.39-3.1 3.1-3.1h4V7H7c-2.76.0-5 2.24-5 5s2.24 5 5 5h4v-1.9H7c-1.71.0-3.1-1.39-3.1-3.1zM8 13h8v-2H8v2zm9-6h-4v1.9h4c1.71.0 3.1 1.39 3.1 3.1s-1.39 3.1-3.1 3.1h-4V17h4c2.76.0 5-2.24 5-5s-2.24-5-5-5z"></path>
    </svg></a>
</h2>
<p>We can start by loading the tidymodels metapackage, and splitting our data into training and testing sets.</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f0f0f0;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-r" data-lang="r"><span style="color:#06287e">library</span>(tidymodels)

<span style="color:#06287e">set.seed</span>(<span style="color:#40a070">123</span>)
vb_split <span style="color:#666">&lt;-</span> <span style="color:#06287e">initial_split</span>(vb_df, strata <span style="color:#666">=</span> win)
vb_train <span style="color:#666">&lt;-</span> <span style="color:#06287e">training</span>(vb_split)
vb_test <span style="color:#666">&lt;-</span> <span style="color:#06287e">testing</span>(vb_split)
</code></pre></div><p>An XGBoost model is based on trees, so we don&rsquo;t need to do much preprocessing for our data; we don&rsquo;t need to worry about the factors or centering or scaling our data. Let&rsquo;s just go straight to setting up our model specification. Sounds great, right? On the other hand, we are going to tune <strong>a lot</strong> of model hyperparameters.</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f0f0f0;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-r" data-lang="r">xgb_spec <span style="color:#666">&lt;-</span> <span style="color:#06287e">boost_tree</span>(
  trees <span style="color:#666">=</span> <span style="color:#40a070">1000</span>,
  tree_depth <span style="color:#666">=</span> <span style="color:#06287e">tune</span>(), min_n <span style="color:#666">=</span> <span style="color:#06287e">tune</span>(),
  loss_reduction <span style="color:#666">=</span> <span style="color:#06287e">tune</span>(),                     <span style="color:#60a0b0;font-style:italic">## first three: model complexity</span>
  sample_size <span style="color:#666">=</span> <span style="color:#06287e">tune</span>(), mtry <span style="color:#666">=</span> <span style="color:#06287e">tune</span>(),         <span style="color:#60a0b0;font-style:italic">## randomness</span>
  learn_rate <span style="color:#666">=</span> <span style="color:#06287e">tune</span>()                          <span style="color:#60a0b0;font-style:italic">## step size</span>
) <span style="color:#666">%&gt;%</span>
  <span style="color:#06287e">set_engine</span>(<span style="color:#4070a0">&#34;xgboost&#34;</span>) <span style="color:#666">%&gt;%</span>
  <span style="color:#06287e">set_mode</span>(<span style="color:#4070a0">&#34;classification&#34;</span>)

xgb_spec
</code></pre></div><pre tabindex="0"><code>## Boosted Tree Model Specification (classification)
##
## Main Arguments:
##   mtry = tune()
##   trees = 1000
##   min_n = tune()
##   tree_depth = tune()
##   learn_rate = tune()
##   loss_reduction = tune()
##   sample_size = tune()
##
## Computational engine: xgboost
</code></pre><p>YIKES. ğŸ˜© Well, let&rsquo;s set up possible values for these hyperparameters to try. Let&rsquo;s use a space-filling design so we can cover the hyperparameter space as well as possible.</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f0f0f0;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-r" data-lang="r">xgb_grid <span style="color:#666">&lt;-</span> <span style="color:#06287e">grid_latin_hypercube</span>(
  <span style="color:#06287e">tree_depth</span>(),
  <span style="color:#06287e">min_n</span>(),
  <span style="color:#06287e">loss_reduction</span>(),
  sample_size <span style="color:#666">=</span> <span style="color:#06287e">sample_prop</span>(),
  <span style="color:#06287e">finalize</span>(<span style="color:#06287e">mtry</span>(), vb_train),
  <span style="color:#06287e">learn_rate</span>(),
  size <span style="color:#666">=</span> <span style="color:#40a070">30</span>
)

xgb_grid
</code></pre></div><pre tabindex="0"><code>## # A tibble: 30 x 6
##    tree_depth min_n loss_reduction sample_size  mtry    learn_rate
##         &lt;int&gt; &lt;int&gt;          &lt;dbl&gt;       &lt;dbl&gt; &lt;int&gt;         &lt;dbl&gt;
##  1         13     9    0.000000191       0.488     6 0.000147     
##  2          4    17    0.0000121         0.661    10 0.00000000287
##  3          7    18    0.0000432         0.151     2 0.0713       
##  4         12    22    0.00000259        0.298     8 0.0000759    
##  5         10    35   16.1               0.676     6 0.00000000111
##  6          4    21    0.673             0.957     7 0.00000000786
##  7          7    25    0.244             0.384     9 0.0000000469 
##  8          7     3    8.48              0.775     6 0.000000555  
##  9          6     8    0.0000915         0.522     6 0.00000106   
## 10         11    37    0.00000109        0.886     9 0.0000000136 
## # â€¦ with 20 more rows
</code></pre><p>Notice that we had to treat <code>mtry()</code> differently because it depends on the actual number of predictors in the data.</p>
<p>Let&rsquo;s put the model specification into a workflow for convenience. Since we don&rsquo;t have any complicated data preprocessing, we can use <code>add_formula()</code> as our data preprocessor.</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f0f0f0;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-r" data-lang="r">xgb_wf <span style="color:#666">&lt;-</span> <span style="color:#06287e">workflow</span>() <span style="color:#666">%&gt;%</span>
  <span style="color:#06287e">add_formula</span>(win <span style="color:#666">~</span> .) <span style="color:#666">%&gt;%</span>
  <span style="color:#06287e">add_model</span>(xgb_spec)

xgb_wf
</code></pre></div><pre tabindex="0"><code>## â•â• Workflow â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
## Preprocessor: Formula
## Model: boost_tree()
## 
## â”€â”€ Preprocessor â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
## win ~ .
## 
## â”€â”€ Model â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
## Boosted Tree Model Specification (classification)
## 
## Main Arguments:
##   mtry = tune()
##   trees = 1000
##   min_n = tune()
##   tree_depth = tune()
##   learn_rate = tune()
##   loss_reduction = tune()
##   sample_size = tune()
## 
## Computational engine: xgboost
</code></pre><p>Next, let&rsquo;s create cross-validation resamples for tuning our model.</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f0f0f0;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-r" data-lang="r"><span style="color:#06287e">set.seed</span>(<span style="color:#40a070">123</span>)
vb_folds <span style="color:#666">&lt;-</span> <span style="color:#06287e">vfold_cv</span>(vb_train, strata <span style="color:#666">=</span> win)

vb_folds
</code></pre></div><pre tabindex="0"><code>## #  10-fold cross-validation using stratification 
## # A tibble: 10 x 2
##    splits               id    
##    &lt;named list&gt;         &lt;chr&gt; 
##  1 &lt;split [19.3K/2.1K]&gt; Fold01
##  2 &lt;split [19.3K/2.1K]&gt; Fold02
##  3 &lt;split [19.3K/2.1K]&gt; Fold03
##  4 &lt;split [19.3K/2.1K]&gt; Fold04
##  5 &lt;split [19.3K/2.1K]&gt; Fold05
##  6 &lt;split [19.3K/2.1K]&gt; Fold06
##  7 &lt;split [19.3K/2.1K]&gt; Fold07
##  8 &lt;split [19.3K/2.1K]&gt; Fold08
##  9 &lt;split [19.3K/2.1K]&gt; Fold09
## 10 &lt;split [19.4K/2.1K]&gt; Fold10
</code></pre><p>IT&rsquo;S TIME TO TUNE. We use <code>tune_grid()</code> with our tuneable workflow, our resamples, and our grid of parameters to try. Let&rsquo;s use <code>control_grid(save_pred = TRUE)</code> so we can explore the predictions afterwards.</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f0f0f0;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-r" data-lang="r">doParallel<span style="color:#666">::</span><span style="color:#06287e">registerDoParallel</span>()

<span style="color:#06287e">set.seed</span>(<span style="color:#40a070">234</span>)
xgb_res <span style="color:#666">&lt;-</span> <span style="color:#06287e">tune_grid</span>(
  xgb_wf,
  resamples <span style="color:#666">=</span> vb_folds,
  grid <span style="color:#666">=</span> xgb_grid,
  control <span style="color:#666">=</span> <span style="color:#06287e">control_grid</span>(save_pred <span style="color:#666">=</span> <span style="color:#007020;font-weight:bold">TRUE</span>)
)

xgb_res
</code></pre></div><pre tabindex="0"><code>## #  10-fold cross-validation using stratification 
## # A tibble: 10 x 5
##    splits             id     .metrics        .notes         .predictions        
##    &lt;named list&gt;       &lt;chr&gt;  &lt;list&gt;          &lt;list&gt;         &lt;list&gt;              
##  1 &lt;split [19.3K/2.1â€¦ Fold01 &lt;tibble [60 Ã— â€¦ &lt;tibble [0 Ã— â€¦ &lt;tibble [64,500 Ã— 1â€¦
##  2 &lt;split [19.3K/2.1â€¦ Fold02 &lt;tibble [60 Ã— â€¦ &lt;tibble [0 Ã— â€¦ &lt;tibble [64,500 Ã— 1â€¦
##  3 &lt;split [19.3K/2.1â€¦ Fold03 &lt;tibble [60 Ã— â€¦ &lt;tibble [0 Ã— â€¦ &lt;tibble [64,500 Ã— 1â€¦
##  4 &lt;split [19.3K/2.1â€¦ Fold04 &lt;tibble [60 Ã— â€¦ &lt;tibble [0 Ã— â€¦ &lt;tibble [64,500 Ã— 1â€¦
##  5 &lt;split [19.3K/2.1â€¦ Fold05 &lt;tibble [60 Ã— â€¦ &lt;tibble [0 Ã— â€¦ &lt;tibble [64,500 Ã— 1â€¦
##  6 &lt;split [19.3K/2.1â€¦ Fold06 &lt;tibble [60 Ã— â€¦ &lt;tibble [0 Ã— â€¦ &lt;tibble [64,500 Ã— 1â€¦
##  7 &lt;split [19.3K/2.1â€¦ Fold07 &lt;tibble [60 Ã— â€¦ &lt;tibble [0 Ã— â€¦ &lt;tibble [64,500 Ã— 1â€¦
##  8 &lt;split [19.3K/2.1â€¦ Fold08 &lt;tibble [60 Ã— â€¦ &lt;tibble [0 Ã— â€¦ &lt;tibble [64,500 Ã— 1â€¦
##  9 &lt;split [19.3K/2.1â€¦ Fold09 &lt;tibble [60 Ã— â€¦ &lt;tibble [0 Ã— â€¦ &lt;tibble [64,500 Ã— 1â€¦
## 10 &lt;split [19.4K/2.1â€¦ Fold10 &lt;tibble [60 Ã— â€¦ &lt;tibble [0 Ã— â€¦ &lt;tibble [64,440 Ã— 1â€¦
</code></pre><p>This takes a while to finish on my computer (and makes my fans run!) but we did it. ğŸ’ª</p>




<h2 id="explore-results">Explore results
  <a href="#explore-results"><svg class="anchor-symbol" aria-hidden="true" height="26" width="26" viewBox="0 0 22 22" xmlns="http://www.w3.org/2000/svg">
      <path d="M0 0h24v24H0z" fill="currentColor"></path>
      <path d="M3.9 12c0-1.71 1.39-3.1 3.1-3.1h4V7H7c-2.76.0-5 2.24-5 5s2.24 5 5 5h4v-1.9H7c-1.71.0-3.1-1.39-3.1-3.1zM8 13h8v-2H8v2zm9-6h-4v1.9h4c1.71.0 3.1 1.39 3.1 3.1s-1.39 3.1-3.1 3.1h-4V17h4c2.76.0 5-2.24 5-5s-2.24-5-5-5z"></path>
    </svg></a>
</h2>
<p>We can explore the metrics for all these models.</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f0f0f0;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-r" data-lang="r"><span style="color:#06287e">collect_metrics</span>(xgb_res)
</code></pre></div><pre tabindex="0"><code>## # A tibble: 60 x 11
##     mtry min_n tree_depth learn_rate loss_reduction sample_size .metric
##    &lt;int&gt; &lt;int&gt;      &lt;int&gt;      &lt;dbl&gt;          &lt;dbl&gt;       &lt;dbl&gt; &lt;chr&gt;  
##  1     1    23          9    1.64e-3   0.00000854         0.117 accuraâ€¦
##  2     1    23          9    1.64e-3   0.00000854         0.117 roc_auc
##  3     2    18          7    7.13e-2   0.0000432          0.151 accuraâ€¦
##  4     2    18          7    7.13e-2   0.0000432          0.151 roc_auc
##  5     2    32          3    1.30e-7   1.16               0.497 accuraâ€¦
##  6     2    32          3    1.30e-7   1.16               0.497 roc_auc
##  7     2    40         10    3.31e-4   0.0000000486       0.429 accuraâ€¦
##  8     2    40         10    3.31e-4   0.0000000486       0.429 roc_auc
##  9     3     5         14    3.56e-3   0.122              0.701 accuraâ€¦
## 10     3     5         14    3.56e-3   0.122              0.701 roc_auc
## # â€¦ with 50 more rows, and 4 more variables: .estimator &lt;chr&gt;, mean &lt;dbl&gt;,
## #   n &lt;int&gt;, std_err &lt;dbl&gt;
</code></pre><p>We can also use visualization to understand our results.</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f0f0f0;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-r" data-lang="r">xgb_res <span style="color:#666">%&gt;%</span>
  <span style="color:#06287e">collect_metrics</span>() <span style="color:#666">%&gt;%</span>
  <span style="color:#06287e">filter</span>(.metric <span style="color:#666">==</span> <span style="color:#4070a0">&#34;roc_auc&#34;</span>) <span style="color:#666">%&gt;%</span>
  <span style="color:#06287e">select</span>(mean, mtry<span style="color:#666">:</span>sample_size) <span style="color:#666">%&gt;%</span>
  <span style="color:#06287e">pivot_longer</span>(mtry<span style="color:#666">:</span>sample_size,
               values_to <span style="color:#666">=</span> <span style="color:#4070a0">&#34;value&#34;</span>,
               names_to <span style="color:#666">=</span> <span style="color:#4070a0">&#34;parameter&#34;</span>
  ) <span style="color:#666">%&gt;%</span>
  <span style="color:#06287e">ggplot</span>(<span style="color:#06287e">aes</span>(value, mean, color <span style="color:#666">=</span> parameter)) <span style="color:#666">+</span>
  <span style="color:#06287e">geom_point</span>(alpha <span style="color:#666">=</span> <span style="color:#40a070">0.8</span>, show.legend <span style="color:#666">=</span> <span style="color:#007020;font-weight:bold">FALSE</span>) <span style="color:#666">+</span>
  <span style="color:#06287e">facet_wrap</span>(<span style="color:#666">~</span>parameter, scales <span style="color:#666">=</span> <span style="color:#4070a0">&#34;free_x&#34;</span>) <span style="color:#666">+</span>
  <span style="color:#06287e">labs</span>(x <span style="color:#666">=</span> <span style="color:#007020;font-weight:bold">NULL</span>, y <span style="color:#666">=</span> <span style="color:#4070a0">&#34;AUC&#34;</span>)
</code></pre></div><img src="/blog/xgboost-tune-volleyball/index_files/figure-html/unnamed-chunk-13-1.png" width="2400" />
<p>Remember that we used a space-filling design for the parameters to try. It looks like higher values for tree depth were better, but other than that, the main thing I take away from this plot is that there are several combinations of parameters that perform well.</p>
<p>What are the best performing sets of parameters?</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f0f0f0;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-r" data-lang="r"><span style="color:#06287e">show_best</span>(xgb_res, <span style="color:#4070a0">&#34;roc_auc&#34;</span>)
</code></pre></div><pre tabindex="0"><code>## # A tibble: 5 x 11
##    mtry min_n tree_depth learn_rate loss_reduction sample_size .metric
##   &lt;int&gt; &lt;int&gt;      &lt;int&gt;      &lt;dbl&gt;          &lt;dbl&gt;       &lt;dbl&gt; &lt;chr&gt;  
## 1     5    25          4  0.0195      0.00112            0.977 roc_auc
## 2     5    33         14  0.0332      0.0000000159       0.864 roc_auc
## 3     2    18          7  0.0713      0.0000432          0.151 roc_auc
## 4     6     9         13  0.000147    0.000000191        0.488 roc_auc
## 5     8    11         14  0.0000135   0.000570           0.453 roc_auc
## # â€¦ with 4 more variables: .estimator &lt;chr&gt;, mean &lt;dbl&gt;, n &lt;int&gt;, std_err &lt;dbl&gt;
</code></pre><p>There may have been lots of parameters, but we were able to get good performance with several different combinations. Let&rsquo;s choose the best one.</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f0f0f0;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-r" data-lang="r">best_auc <span style="color:#666">&lt;-</span> <span style="color:#06287e">select_best</span>(xgb_res, <span style="color:#4070a0">&#34;roc_auc&#34;</span>)
best_auc
</code></pre></div><pre tabindex="0"><code>## # A tibble: 1 x 6
##    mtry min_n tree_depth learn_rate loss_reduction sample_size
##   &lt;int&gt; &lt;int&gt;      &lt;int&gt;      &lt;dbl&gt;          &lt;dbl&gt;       &lt;dbl&gt;
## 1     5    25          4     0.0195        0.00112       0.977
</code></pre><p>Now let&rsquo;s finalize our tuneable workflow with these parameter values.</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f0f0f0;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-r" data-lang="r">final_xgb <span style="color:#666">&lt;-</span> <span style="color:#06287e">finalize_workflow</span>(
  xgb_wf,
  best_auc
)

final_xgb
</code></pre></div><pre tabindex="0"><code>## â•â• Workflow â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
## Preprocessor: Formula
## Model: boost_tree()
## 
## â”€â”€ Preprocessor â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
## win ~ .
## 
## â”€â”€ Model â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
## Boosted Tree Model Specification (classification)
## 
## Main Arguments:
##   mtry = 5
##   trees = 1000
##   min_n = 25
##   tree_depth = 4
##   learn_rate = 0.019501844932014
##   loss_reduction = 0.00112048286512169
##   sample_size = 0.977300804650877
## 
## Computational engine: xgboost
</code></pre><p>Instead of <code>tune()</code> placeholders, we now have real values for all the model hyperparameters.</p>
<p>What are the most important parameters for 
<a href="https://koalaverse.github.io/vip/" target="_blank" rel="noopener">variable importance</a>?</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f0f0f0;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-r" data-lang="r"><span style="color:#06287e">library</span>(vip)

final_xgb <span style="color:#666">%&gt;%</span>
  <span style="color:#06287e">fit</span>(data <span style="color:#666">=</span> vb_train) <span style="color:#666">%&gt;%</span>
  <span style="color:#06287e">pull_workflow_fit</span>() <span style="color:#666">%&gt;%</span>
  <span style="color:#06287e">vip</span>(geom <span style="color:#666">=</span> <span style="color:#4070a0">&#34;point&#34;</span>)
</code></pre></div><img src="/blog/xgboost-tune-volleyball/index_files/figure-html/unnamed-chunk-17-1.png" width="2100" />
<p>The predictors that are most important in a team winning vs. losing their match are the number of kills, errors, and attacks. There is almost no difference between the two circuits, and very little difference by gender.</p>
<p>It&rsquo;s time to go back to the testing set! Let&rsquo;s use <code>last_fit()</code> to <em>fit</em> our model one last time on the training data and <em>evaluate</em> our model one last time on the testing set. Notice that this is the first time we have used the testing data during this whole modeling analysis.</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f0f0f0;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-r" data-lang="r">final_res <span style="color:#666">&lt;-</span> <span style="color:#06287e">last_fit</span>(final_xgb, vb_split)

<span style="color:#06287e">collect_metrics</span>(final_res)
</code></pre></div><pre tabindex="0"><code>## # A tibble: 2 x 3
##   .metric  .estimator .estimate
##   &lt;chr&gt;    &lt;chr&gt;          &lt;dbl&gt;
## 1 accuracy binary         0.843
## 2 roc_auc  binary         0.928
</code></pre><p>Our results here indicate that we did not overfit during the tuning process. We can also create a ROC curve for the testing set.</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f0f0f0;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-r" data-lang="r">final_res <span style="color:#666">%&gt;%</span>
  <span style="color:#06287e">collect_predictions</span>() <span style="color:#666">%&gt;%</span>
  <span style="color:#06287e">roc_curve</span>(win, .pred_win) <span style="color:#666">%&gt;%</span>
  <span style="color:#06287e">ggplot</span>(<span style="color:#06287e">aes</span>(x <span style="color:#666">=</span> <span style="color:#40a070">1</span> <span style="color:#666">-</span> specificity, y <span style="color:#666">=</span> sensitivity)) <span style="color:#666">+</span>
  <span style="color:#06287e">geom_line</span>(size <span style="color:#666">=</span> <span style="color:#40a070">1.5</span>, color <span style="color:#666">=</span> <span style="color:#4070a0">&#34;midnightblue&#34;</span>) <span style="color:#666">+</span>
  <span style="color:#06287e">geom_abline</span>(
    lty <span style="color:#666">=</span> <span style="color:#40a070">2</span>, alpha <span style="color:#666">=</span> <span style="color:#40a070">0.5</span>,
    color <span style="color:#666">=</span> <span style="color:#4070a0">&#34;gray50&#34;</span>,
    size <span style="color:#666">=</span> <span style="color:#40a070">1.2</span>
  )
</code></pre></div><img src="/blog/xgboost-tune-volleyball/index_files/figure-html/unnamed-chunk-19-1.png" width="1800" />

        
        <details closed class="f6 fw7 input-reset">
  <dl class="f6 lh-copy">
    <dt class="fw7">Posted on:</dt>
    <dd class="fw5 ml0">May 21, 2020</dd>
  </dl>
  <dl class="f6 lh-copy">
    <dt class="fw7">Length:</dt>
    <dd class="fw5 ml0">11 minute read, 2258 words</dd>
  </dl>
  
  <dl class="f6 lh-copy">
    <dt class="fw7">Categories:</dt>
    <dd class="fw5 ml0"> <a href="https://juliasilge.com/categories/rstats">rstats</a>  <a href="https://juliasilge.com/categories/tidymodels">tidymodels</a> </dd>
  </dl>
  
  
  
  <dl class="f6 lh-copy">
    <dt class="fw7">Tags:</dt>
    <dd class="fw5 ml0"> <a href="https://juliasilge.com/tags/rstats">rstats</a>  <a href="https://juliasilge.com/tags/tidymodels">tidymodels</a> </dd>
  </dl>
  
  <dl class="f6 lh-copy">
    <dt class="fw7">See Also:</dt>
    
    <dd class="fw5 ml0"><a href="/blog/educational-attainment/">Educational attainment in #TidyTuesday UK towns</a></dd>
    
    <dd class="fw5 ml0"><a href="/blog/polling-places/">Changes in #TidyTuesday US polling places</a></dd>
    
    <dd class="fw5 ml0"><a href="/blog/doctor-who-bayes/">Empirical Bayes for #TidyTuesday Doctor Who episodes</a></dd>
    
  </dl>
</details>

      </section>
      <footer class="post-footer">
        <div class="post-pagination dt w-100 mt4 mb2">
  
  
    <a class="prev dtc pr2 tl v-top fw6"
    href="https://juliasilge.com/blog/tidylo-cran/">&larr; tidylo is now on CRAN! ğŸ‰</a>
  
  
  
    <a class="next dtc pl2 tr v-top fw6"
    href="https://juliasilge.com/blog/tidymodels-ml-course/">Learn tidymodels with my supervised machine learning course &rarr;</a>
  
</div>

      </footer>
    </article>
    
      
<div class="post-comments pa0 pa4-l mt4">
  
  <script src="https://utteranc.es/client.js"
          repo="juliasilge/juliasilge.com"
          issue-term="title"
          theme="github-light"
          label="comments :speech_balloon:"
          crossorigin="anonymous"
          async
          type="text/javascript">
  </script>
  
</div>

    
  </section>
</main>
<footer class="site-footer pv4 bt b--transparent ph5" role="contentinfo">
  <nav class="db dt-l w-100">
    <p class="site-copyright f7 db dtc-l v-mid w-100 w-33-l tc tl-l pv2 pv0-l mv0 lh-copy">
      &copy; 2024 Julia Silge
      <span class="middot-divider"></span>
      Made with <span xmlns:dct="http://purl.org/dc/terms/" property="dct:title"><a xmlns:dct="http://purl.org/dc/terms/" href="https://github.com/hugo-apero/" rel="dct:source">Hugo ApÃ©ro</a></span>.
      <br />
      
Based on <span xmlns:dct="http://purl.org/dc/terms/" property="dct:title"><a xmlns:dct="http://purl.org/dc/terms/" href="https://github.com/formspree/blogophonic-hugo" rel="dct:source">Blogophonic</a></span> by <a xmlns:cc="http://creativecommons.org/ns#" href="https://formspree.io" property="cc:attributionName" rel="cc:attributionURL">Formspree</a>.
    </p>
    
    <div class="site-links f6 db dtc-l v-mid w-100 w-67-l tc tr-l pv2 pv0-l mv0">
      
      <a class="dib pv1 ph2 link" href="/license/" title="License">License</a>
      
    </div>
  </nav>
  
    <script>

    var i, text, code, codes = document.getElementsByTagName('code');
    for (let i = 0; i < codes.length;) {
      code = codes[i];
      if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
        text = code.textContent;
        if (/^\$[^$]/.test(text) && /[^$]\$$/.test(text)) {
          text = text.replace(/^\$/, '\\(').replace(/\$$/, '\\)');
          code.textContent = text;
        }
        if (/^\\\((.|\s)+\\\)$/.test(text) ||
            /^\\\[(.|\s)+\\\]$/.test(text) ||
            /^\$(.|\s)+\$$/.test(text) ||
            /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
          code.outerHTML = code.innerHTML;  
          continue;
        }
      }
      i++;
    }
</script>

  
    
    
      <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.13.13/dist/katex.min.css" integrity="sha384-RZU/ijkSsFbcmivfdRBQDtwuwVqK7GMOw6IMvKyeWL2K5UAlyp6WonmB8m7Jd0Hn" crossorigin="anonymous">
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.13.13/dist/katex.min.js" integrity="sha384-pK1WpvzWVBQiP0/GjnvRxV4mOb0oxFuyRxJlk6vVw146n3egcN5C925NCP7a7BY8" crossorigin="anonymous"></script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.13.13/dist/contrib/auto-render.min.js" integrity="sha384-vZTG03m+2yp6N6BNi5iM4rW4oIwk5DfcNdFfxkk9ZWpDriOkXX8voJBFrAO7MpVl" crossorigin="anonymous" onload="renderMathInElement(document.body);"></script>



    
  
  
</footer>

      </div>
    </body>
</html>
